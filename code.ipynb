{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Organizing Image Data\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Timing\n",
    "from tqdm.auto import tqdm\n",
    "from time import time\n",
    "\n",
    "# Torch imports\n",
    "from torch import device\n",
    "from torch import cuda\n",
    "from torch import Generator\n",
    "from torch import sum\n",
    "from torch import where\n",
    "from torch import argmax\n",
    "from torch import tensor\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.nn import Linear\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = \"OBSCURED\"\n",
    "folders = os.listdir(path)\n",
    "rescale = 100\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(path + '/' + folder)\n",
    "    for idx, file in enumerate(tqdm(files, desc=\"Files Renamed/Resized: \")):\n",
    "        image = Image.open(os.path.join(path, folder, file))\n",
    "        image = image.resize((rescale, rescale))\n",
    "        new_path = os.path.join(path, folder, str(idx))\n",
    "        image.save(str(new_path) + \".png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7864dfbcb34c59d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ResNetClassifier(Module):\n",
    "    def __init__(self, lr, tol, batch_size, epochs, num_classes, scale, data_path, seed):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "\n",
    "\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.scale = scale\n",
    "        self.data_path = data_path\n",
    "        self.seed = seed\n",
    "        self.device = device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.epoch_acc_history = []\n",
    "        self.test_loss = -1\n",
    "        self.test_acc = -1\n",
    "\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT).to(self.device)\n",
    "\n",
    "        self.in_dims = self.model.fc.in_features\n",
    "        self.fc = Linear(in_features=self.in_dims, out_features=num_classes)\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr = self.lr)\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "        self.train_data_loader = None\n",
    "        self.test_data_loader = None\n",
    "        self.get_data()\n",
    "\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        batch_data = batch_data.clone().detach().to(self.device)\n",
    "        output = self.model(batch_data)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        tf = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "\n",
    "        all_data = datasets.ImageFolder(self.data_path, transform=tf)\n",
    "        train_data, test_data = random_split(all_data, [0.75, 0.25],\n",
    "                                             generator=Generator().manual_seed(self.seed))\n",
    "        self.train_data_loader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "        self.test_data_loader = DataLoader(test_data, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "    def train_(self):\n",
    "        time_started = time()\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            header = f\"Epoch {i+1}/{self.epochs}\"\n",
    "            print(header)\n",
    "            print(\"-\" * len(header))\n",
    "\n",
    "            loader = self.train_data_loader\n",
    "            self.train()\n",
    "\n",
    "            # For plotting and statistics\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = []\n",
    "\n",
    "            # Main training loop\n",
    "            for in_data, label in loader:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Get model prediction and determine how well it did\n",
    "                label = label.to(self.device)\n",
    "                prediction = self.forward(in_data)\n",
    "                classes = argmax(prediction, dim=1)\n",
    "\n",
    "                wrong = where(tensor(classes != label).to(self.device),\n",
    "                              tensor([1.]).to(self.device),\n",
    "                              tensor([0.]).to(self.device))\n",
    "\n",
    "                # Calculate loss and accuracy\n",
    "                acc = 1 - sum(wrong) / self.batch_size\n",
    "                batch_loss = self.loss(prediction, label)\n",
    "                epoch_loss += batch_loss.item()\n",
    "\n",
    "                # Train through backpropagation\n",
    "                batch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                self.acc_history.append(acc.item())\n",
    "                epoch_acc.append(acc.item())\n",
    "\n",
    "            elapsed = time() - time_started\n",
    "            print(f\"Finished epoch {i+1} with loss {epoch_loss} and accuracy of {np.mean(epoch_acc)} in time \"\n",
    "                  f\"{int((elapsed // 60) // 60)}:{int(elapsed // 60)}:{int(elapsed % 60)}\")\n",
    "\n",
    "            self.loss_history.append(epoch_loss)\n",
    "            self.epoch_acc_history.append(np.mean(epoch_acc))\n",
    "            print()\n",
    "\n",
    "        print(\"Training complete...\")\n",
    "\n",
    "\n",
    "    def test_(self):\n",
    "        self.eval()\n",
    "\n",
    "        time_started = time()\n",
    "        total_loss = 0\n",
    "        total_acc = []\n",
    "\n",
    "        for in_data, label in self.test_data_loader:\n",
    "\n",
    "            # Compare correct answers to model\n",
    "            label = label.to(self.device)\n",
    "            prediction = self.forward(in_data)\n",
    "            classes = argmax(prediction, dim=1)\n",
    "\n",
    "            wrong = where(tensor(classes != label).to(self.device),\n",
    "                          tensor([1.]).to(self.device),\n",
    "                          tensor([0.]).to(self.device))\n",
    "\n",
    "            acc = 1 - sum(wrong) / self.batch_size\n",
    "            batch_loss = self.loss(prediction, label)\n",
    "\n",
    "            total_acc.append(acc.item())\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "        elapsed = int(time() - time_started)\n",
    "        self.test_acc = np.mean(total_acc)\n",
    "        self.test_loss = total_loss\n",
    "\n",
    "        print(f\"Finished with loss {self.test_loss} and accuracy of {self.test_acc} in {elapsed // 60}:{elapsed % 60}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8207157103b9de38"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = ResNetClassifier(lr=0.01, tol=2, batch_size=64, epochs=5, num_classes=2, scale=100, data_path=\"OBSCURED\", seed=251)\n",
    "model.train_()\n",
    "model.test_()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52935d2d793cfc5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "v = input(\"Enter version #: \")\n",
    "fig = int(input(\"Enter figure #: \"))\n",
    "epoch_dims = np.arange(1, len(model.loss_history)+1, 1)\n",
    "path = 'data-graphs/'\n",
    "v_num = int(v[0])\n",
    "\n",
    "# Graph 1\n",
    "plt.plot(model.loss_history, marker='o', color='darkred')\n",
    "plt.title(f\"Figure {fig}: Cross-Entropy Training Loss vs. Number of Epochs\\nfor Version {v_num}\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Cross-Entropy Training Loss\")\n",
    "plt.xticks(np.arange(len(model.loss_history)), epoch_dims)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(path + 'v' + v + \"-train-loss-graph.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Graph 2\n",
    "plt.plot(model.epoch_acc_history, marker='o', color='darkred')\n",
    "plt.title(f\"Figure {fig+2}: Training Accuracy vs. Number of Epochs\\nfor Version {v_num}\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xticks(np.arange(len(model.epoch_acc_history)), epoch_dims)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(path + 'v' + v + \"-epoch-acc-graph.png\", bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a7599d4d9ede75d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def write_to(fw, arr, header):\n",
    "    fw.write(header + '\\n[' + str(arr[0]))\n",
    "    for num in range(1, len(arr)):\n",
    "        fw.write(', ' + str(arr[num]))\n",
    "    fw.write(']\\n\\n')\n",
    "\n",
    "\n",
    "try: v\n",
    "except NameError: v = input(\"Enter version: \")\n",
    "\n",
    "with open(f'data-graphs/v{v}-data.txt', 'w') as f_out:\n",
    "    write_to(f_out, model.loss_history, \"Training Loss\")\n",
    "    write_to(f_out, model.epoch_acc_history, \"Training Accuracy (Per Epoch)\")\n",
    "\n",
    "    f_out.write(f\"Testing Loss, Accuracy\\n{model.test_loss}, {model.test_acc}\\n\\n\")\n",
    "\n",
    "    write_to(f_out, model.acc_history, \"Training Accuracy (Per Batch)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5e9c8a230cc717"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
